{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Model Selection\n",
    "\n",
    "In this notebook I will demonstrate my understanding of overfitting and underfitting using regression as an example. First I will generate a 1-dimensional feature space and an array of values for each row in the feature space. Then I will create regresion estimators based on linear regression (`x**1`) and polynomial regression (2nd, 4th and 6th degree, i.e. `x**2`, `x**4`  and `x**6`). I will show that the higher the polynomial, the better the fit for the train set, but the worse the fit for the test set. I will visually support my case.\n",
    "\n",
    "I will re-use code from the [Python Data Science Handbook](http://bit.ly/2y3xzKw). To proof my understanding of the code I am re-using, I will comment on the code in my own words, both in MarkDown cells and in frequent code comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. create test data\n",
    "\n",
    "[your comment goes here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19514bc1be0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEtdJREFUeJzt3X+Q3PVdx/HXu5ejs2mZXpQTm4XzYqc9pEC5srbY1I4N\n1Su0lROZgaq0w9TJOE4rZZyTxD+E0XGIxrHoqHUytNpOO4JC5hotNjATapUW7IULTUOIjVR+XKhc\nC2cVTrmEt3/cbrnc7e59d7/f3e/n+/k+HzOZ3O19s/v5kPDaz/f9+bHm7gIAFN+r8m4AACAbBDoA\nRIJAB4BIEOgAEAkCHQAiQaADQCQIdACIBIEOAJEg0AEgEhv6+WJnnXWWj46O9vMlAaDwDh48+F13\nH17vur4G+ujoqGZmZvr5kgBQeGb2RJLrKLkAQCQIdACIBIEOAJEg0AEgEgQ6AESCQAeASPR12SIQ\nuunZOe3ef0wnFha1eaiiqYkxTY5X824WkAiBDtRNz85p597DWlw6JUmaW1jUzr2HJYlQRyFQcgHq\ndu8/9oMwb1hcOqXd+4/l1CKgMwQ6UHdiYbGjx4HQEOhA3eahSkePA6Eh0IG6qYkxVQYHTnusMjig\nqYmxnFoEdGbdQDezT5vZs2b2zRWP/ZCZ3Wdm36r/vqm3zQR6b3K8qluvulDVoYpMUnWooluvupAJ\nURSGuXv7C8zeJel/JH3W3S+oP/aHkp5z911mtkPSJne/ab0Xq9VqzmmLQLGwlDN/ZnbQ3WvrXbfu\nCN3dvyLpuVUPXynpM/WvPyNpsuMWAgheYynn3MKiXK8s5Zyencu7aWii2xr62e7+TP3r70g6u9WF\nZrbdzGbMbGZ+fr7LlwOQB5ZytjY9O6etuw5oy44vauuuA0G8yaWeFPXlmk3Luo2773H3mrvXhofX\n/cANAAFhKWdzod65dBvo/2lmr5ek+u/PZtckAKFgKWdzod65dBvo+yR9uP71hyV9IZvmAAgJSzmb\nC/XOJcmyxb+R9DVJY2b2tJl9RNIuST9rZt+S9J769wAiw1LO5kK9c1n3cC53/2CLH12WcVsABGhy\nvFr6AF9tamLstIPcpDDuXDhtEQA61HiDC219PoEOIHghbm4K8c6FQAcQNM6pT47DuQAELdQlgiEi\n0AEELdQlgiEi0AEELdQlgiEi0AEEjc1NyTEpCiBooS4RDBGBDiB4IS4RDBGBDiBXIa4xLyoCHUBu\nWGOeLSZFAeTmln1HWGOeIUboKAVu68MzPTunhcWlpj9jjXl3CHREj9v6MLUbhbPGvDuUXBA9to6H\nqd0onDXm3SHQET22joep1Sh808ZB7py6RKAjemXdOh7ip9Kv1GoH6M0feHNOLSo+Ah3RK+PW8VA/\nlX4lPt4ue0yKInqdbB2PZTVMu3mDkPrDDtBsEegohSTBEdNqmCLNG8TyJhoCSi5AXUyrYYoyb1CE\n0lCREOhAXZFGtespyrxBTG+iK+U1IU3JBajbPFTRXJPwDm1Um0RRjpyN6U20Ic/SHYGOpspY15ya\nGDvtf0QpzFFtUkWYcIzpTbQhzwlpSi5Yo2x1zcbt8Y13HtKrN7xKmzYOsoyuT4pSGupEnncdjNCx\nRlGWvGVh9e3xwuKSKoMD+sQ1F/e0r2W8A2qmKKWhTuR510GgY40Y65qt5PHmFdPyyCwUoTTUiTxL\nd5RcsEZRlrxlIY83r1hXdmBZnjtgU43QzexGSb8qySUdlnS9u/9vFg1DfmKbHGwnj9vjMt0BlVVe\ndx1dj9DNrCrpNyTV3P0CSQOSrs2qYchPmc7YyGNSrkx3QOivtDX0DZIqZrYkaaOkE+mbhBDEVtds\nJY9JuTLdAaG/ug50d58zsz+S9KSkRUn3uvu9mbUM6JN+v3nFuLIDYTB37+4Pmm2SdLekayQtSPo7\nSXe5++dWXbdd0nZJGhkZueSJJ55I1WAAKBszO+jutfWuS7PK5T2Svu3u8+6+JGmvpHesvsjd97h7\nzd1rw8PDKV4OANBOmhr6k5IuNbONWi65XCZpJpNWAQXBBiGEJE0N/SEzu0vSw5JOSpqVtCerhgGh\nY4MQQpNqY5G73+zu57n7Be5+nbv/X1YNA0LHBiGEhp2iQJfYIITQcJYLSq/bOniMR7+i2Biho9TS\nHBUc49GvKDYCHaWWpg5epiMSUAyUXFBqaevgZTkiAcXACB2lxkFZiAmBHoi8PiW87KiDIyaUXALA\nBpX8cFAWYkKgB6BMn+EZIurgiAUllwCwQQVAFgj0ADAxByALBHoAmk3MSdKLL51kchRAYgR6ABob\nVIYqg6c9/vyLS4l3LQIAgR6IyfGqXvPqtXPUnN4HICkCPSBMjgJIg0APCJOjANIg0ANSpF2L7GwF\nwsPGooAUZdciO1uBMBHogQlt12KzD39gZysQJgIdLbUaia8O8wYmb4F8UUNHS61G4gNmTa9n8hbI\nF4GOllqNuE+5F2byFigTAh0ttRpxNz5qjY9eA8JCDR0tTU2MramZN0bioU3eAiDQ0UZRllECWEag\noy1G4kBxEOiBaLbemyAF0AkCPQDsvASQhVSrXMxsyMzuMrPHzOyomf1UVg0rk3Y7LwEgqbQj9D+R\n9CV3v9rMzpC0MYM2lQ7H5gLIQtcjdDN7naR3SfqUJLn7S+6+kFXDyoRjcwFkIU3JZYukeUl/ZWaz\nZna7mb0mo3YFqVdHxhbp2FwA4UoT6BskvVXSJ919XNILknasvsjMtpvZjJnNzM/Pp3i5fDUmLucW\nFuV6ZeIyi1BvfKYoOy8BpGHu3t0fNPtRSQ+6+2j9+5+WtMPd39fqz9RqNZ+Zmenq9fK2ddcBzTWp\naVeHKnpgx7YcWgSgLMzsoLvX1ruu6xG6u39H0lNm1qgLXCbp0W6fL3RMXAIIXdpVLh+T9Pn6CpfH\nJV2fvklh2jxUaTpCz3Liks1FANJItQ7d3Q+5e83dL3L3SXd/PquGhabXE5e9rNEDKAeOz02o1xOX\nbC4CkBZb/zvQy4OqqNEDSIsReiDYXAQgLUboOWg2+dnuwyQAIAlG6H3WavJTEpuLAKTCCL3P2k1+\nPrBjGwEOoGuM0PuMyU8AvUKg9xmTnwB6hUBPKKuTFjlZEUCvUENPIMuPiGtczxZ/AFkj0BNoN5E5\nOV7t+AyWXm5QAlBeBHoC7SYy+YBnAKGghp5Au4lMzmABEAoCPYF2E5ksQwQQCgI9gXYnLbIMEUAo\nqKEn1GoikzNYAISCQE+JZYgAQkGgZ4BliABCQA0dACJBoANAJKIvuXS6ixMAiirqQGcXJ4Ayibrk\nwi5OAGUSdaCzixNAmUQd6OziBFAmUQc6HyYBoEyinhRlFyeAMok60CV2cQIoj6hLLgBQJqkD3cwG\nzGzWzP4hiwYBALqTxQj9BklHM3geAEAKqQLdzM6R9D5Jt2fTHABAt9JOit4m6bckndnqAjPbLmm7\nJI2MjKR8uf7jLBgARdH1CN3M3i/pWXc/2O46d9/j7jV3rw0PD3f7crlonAUzt7Ao1ytnwUzPzuXd\nNABYI03JZauknzez/5B0h6RtZva5TFoVCM6CAVAkXQe6u+9093PcfVTStZIOuPuvZNayAHAWDIAi\nYR16G5wFA6BIMgl0d/+yu78/i+cKCWfBACiS6Lf+p8FZMACKhEBfB2fBACgKaugAEAkCHQAiQaAD\nQCQIdACIBIEOAJEg0AEgEgQ6AESCQAeASBDoABAJAh0AIkGgA0AkCHQAiASBDgCRINABIBIEOgBE\ngkAHgEgQ6AAQCQIdACJBoANAJAh0AIgEgQ4AkSDQASASBDoARIJAB4BIEOgAEAkCHQAi0XWgm9m5\nZna/mT1qZkfM7IYsGwYA6MyGFH/2pKTfdPeHzexMSQfN7D53fzSjtgEAOtD1CN3dn3H3h+tf/7ek\no5KqWTUMANCZNCP0HzCzUUnjkh7K4vmyMD07p937j+nEwqI2D1U0NTGmyXHebwDEK/WkqJm9VtLd\nkj7u7t9v8vPtZjZjZjPz8/NpXy6R6dk57dx7WHMLi3JJcwuL+vidhzT+u/dqenauL20AgH5LFehm\nNqjlMP+8u+9tdo2773H3mrvXhoeH07xcYrv3H9Pi0qk1jz//4pJ27j1MqAOIUtclFzMzSZ+SdNTd\n/zi7JrWWtIxyYmGx5XMsLp3S7v3HKL8AiE6aEfpWSddJ2mZmh+q/rsioXWs0K6O0Gm1vHqq0fa52\ngQ8ARZVmlcu/uLu5+0XufnH91z1ZNm6lZmWUxmh7tamJMVUGB1o+13qBDwBFVJidoq1G1c0enxyv\n6tarLtRQZXDNzyqDA5qaGMu8fQCQt8IEeqtRdePx6dk5bd11QFt2fFFbdx2QJB26+ed02zUXqzpU\nkUmqDlV061UXUj8HEKVM1qH3w9TEmHbuPXxa2aUx2m7U1xs/a9TXpeXROgEOoAwKM0JvlFGajbY7\nqa8DQKwKM0KXTh9tN5Yw3njnIXmL61nNAqBMChXoDatLLK2wmgVAmRSm5LJSq52gK7GaBUDZFHKE\n3q6UYhKHcQEopUKO0FuVUqpDFX3imoslSTfeeUhbdx3g3BYApVHIQG+2E7QyOKB3nzec+HgAAIhN\nIQO91RLG+x+bZ/kigNIqZKC3OnWxk+MBACA2hZsUbbYrdOquR3TLviMt16OzfBFAGRRuhN5syeLS\nKdfC4lLT61m+CKAsCjdC76R8UmX5IoASKVygbx6qaC5BqJukB3Zs632DACAQhSu5rPfhFQ3UzQGU\nTeECfXK8ql+8pCprcw11cwBlVLiSiyTd/9h8yxUt1M0BlFWhAr2x/rxVDZ26OYAyK0ygJzkyl7o5\ngDIrTA19vSNzqZsDKLvCjNDbrT+nbg4ABQr0VuvPq0MV6uYAoAKVXFodmUuZBQCWFWaE3iinNDtl\nEQBQoECXlkOdAAeA5gpTcgEAtJcq0M3svWZ2zMyOm9mOrBoFAOhc14FuZgOS/lzS5ZLOl/RBMzs/\nq4YBADqTZoT+NknH3f1xd39J0h2SrsymWQCATqWZFK1KemrF909Lenu65rTX6rNEAQB9WOViZtsl\nbZekkZGRrp+n2WeJ7tx7WJIIdQBQupLLnKRzV3x/Tv2x07j7HnevuXtteHi46xdrdpbL4tIp3bLv\nSNfPCQAxSRPoX5f0RjPbYmZnSLpW0r5smrVWq7NcFhaXND275n0EAEqn60B395OSPippv6Sjkv7W\n3Xs2XG53NO7u/cd69bIAUBip1qG7+z3u/iZ3f4O7/35WjWqm3Zkt7U5iBICyKMxO0cnxqjZtHGz6\nMz7YAgAKFOiSdPMH3syJiwDQQuEO55I4cREAmilUoEucuAgArRSq5AIAaI1AB4BIEOgAEAkCHQAi\nQaADQCTM3fv3Ymbzkp7I4KnOkvTdDJ6nqMrc/zL3XaL/Ze3/j7n7uqcb9jXQs2JmM+5ey7sdeSlz\n/8vcd4n+l73/66HkAgCRINABIBJFDfQ9eTcgZ2Xuf5n7LtH/sve/rULW0AEAaxV1hA4AWCXoQDez\n95rZMTM7bmY7mvzczOxP6z//hpm9NY929kKCvv9yvc+HzeyrZvaWPNrZK+v1f8V1P2lmJ83s6n62\nr9eS9N/MfsbMDpnZETP7p363sVcS/Nt/nZn9vZk9Uu/79Xm0M0juHuQvSQOS/l3Sj0s6Q9Ijks5f\ndc0Vkv5Rkkm6VNJDebe7j31/h6RN9a8vj6XvSfu/4roDku6RdHXe7e7z3/+QpEcljdS//5G8293H\nvv+2pD+ofz0s6TlJZ+Td9hB+hTxCf5uk4+7+uLu/JOkOSVeuuuZKSZ/1ZQ9KGjKz1/e7oT2wbt/d\n/avu/nz92wclndPnNvZSkr97SfqYpLslPdvPxvVBkv7/kqS97v6kJLl7LP8NkvTdJZ1pZibptVoO\n9JP9bWaYQg70qqSnVnz/dP2xTq8pok779REt36nEYt3+m1lV0i9I+mQf29UvSf7+3yRpk5l92cwO\nmtmH+ta63krS9z+T9BOSTkg6LOkGd3+5P80LW+E+4AKnM7N3aznQ35l3W/rsNkk3ufvLywO10tkg\n6RJJl0mqSPqamT3o7v+Wb7P6YkLSIUnbJL1B0n1m9s/u/v18m5W/kAN9TtK5K74/p/5Yp9cUUaJ+\nmdlFkm6XdLm7f69PbeuHJP2vSbqjHuZnSbrCzE66+3R/mthTSfr/tKTvufsLkl4ws69Ieoukogd6\nkr5fL2mXLxfRj5vZtyWdJ+lf+9PEcIVccvm6pDea2RYzO0PStZL2rbpmn6QP1Ve7XCrpv9z9mX43\ntAfW7buZjUjaK+m6CEdl6/bf3be4+6i7j0q6S9KvRxLmUrJ/+1+Q9E4z22BmGyW9XdLRPrezF5L0\n/Ukt35nIzM6WNCbp8b62MlDBjtDd/aSZfVTSfi3PfH/a3Y+Y2a/Vf/6XWl7dcIWk45Je1PI7d+El\n7PvvSPphSX9RH6We9EgOLUrY/2gl6b+7HzWzL0n6hqSXJd3u7t/Mr9XZSPh3/3uS/trMDmt5hdtN\n7l7GExjXYKcoAEQi5JILAKADBDoARIJAB4BIEOgAEAkCHQAiQaADQCQIdACIBIEOAJH4f7TZeZH9\nI8tdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19514cfe240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code goes here\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data must not be classifiable, it has to be a numerical value\n",
    "\n",
    "#Creates Random data (like in book) \n",
    "#What does rseed describe? It is not the range\n",
    "def make_data(N, err=1.0, rseed=1): \n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y\n",
    "\n",
    "#Create a set of 40 numerical values with the method above\n",
    "X, y = make_data(40)\n",
    "plt.scatter(X, y)#visualizes data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. create the regression pipeline\n",
    "\n",
    "[your comment goes here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'polymodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-fdb606e04559>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m                          LinearRegression(**kwargs))\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mpolymodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m#Plot the graphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'polymodel' is not defined"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#degree-1: y=ax+b\n",
    "poly_model = make_pipeline(PolynomialFeatures(1),LinearRegression(1)) #creates pipeline\n",
    "poly_model.fit(X, y)#fits the model\n",
    "y_fit1 = poly_model.predict(X_test)#tests the model\n",
    "\n",
    "#degree-2: y=ax²+bx+c\n",
    "poly_model = make_pipeline(PolynomialFeatures(2),LinearRegression(2))\n",
    "poly_model.fit(X, y)\n",
    "y_fit2 = poly_model.predict(X_test)\n",
    "\n",
    "#degree-4: y=ax^4+bx^3+cx^2+dx+e\n",
    "poly_model = make_pipeline(PolynomialFeatures(4),LinearRegression())\n",
    "poly_model.fit(X, y)\n",
    "y_fit4 = poly_model.predict(X_test)\n",
    "\n",
    "#degree-6: y=ax^6+bx^5+cx^4+dx^3+ex^2+fx+g\n",
    "poly_model = make_pipeline(PolynomialFeatures(6),LinearRegression())\n",
    "poly_model.fit(X, y)\n",
    "y_fit6 = poly_model.predict(X_test)\n",
    "\n",
    "#degree-20\n",
    "poly_model = make_pipeline(PolynomialFeatures(20),LinearRegression())\n",
    "poly_model.fit(X, y)\n",
    "y_fit20 = poly_model.predict(X_test)\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))\n",
    "\n",
    "polymodel\n",
    "\n",
    "#Plot the graphs\n",
    "axis = plt.axis()\n",
    "plt.plot(X_test, y_fit1, label = 'degree 1') \n",
    "plt.plot(X_test, y_fit2, label = 'degree 2')\n",
    "plt.plot(X_test, y_fit4, label = 'degree 4')\n",
    "plt.plot(X_test, y_fit6, label = 'degree 6')\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. show the regressors\n",
    "\n",
    "[your comment goes here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "# visualize test data \n",
    "plt.scatter(X.ravel(), y, color = 'black')# shows data points\n",
    "axis = plt.axis()\n",
    "plt.plot(X_test.ravel(), y_fit1, label = 'degree 1') \n",
    "plt.plot(X_test.ravel(), y_fit2, label = 'degree 2')\n",
    "plt.plot(X_test.ravel(), y_fit4, label = 'degree 4')\n",
    "plt.plot(X_test.ravel(), y_fit6, label = 'degree 6')\n",
    "plt.plot(X_test.ravel(), y_fit20, label = 'degree 20')\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');\n",
    "\n",
    "#Degree 1 is an extreme example of underfitting and degree 20 of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. show the validation curve\n",
    "\n",
    "[your comment goes here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "#Example from the book, needs to be fitted to my data\n",
    "\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y, 'polynomialfeatures__degree', degree, cv=7)\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. conduct grid search to find the optimal regressor\n",
    "\n",
    "[your comment goes here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
